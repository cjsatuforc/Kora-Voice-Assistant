\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{url}
\usepackage{setspace}
 
%For indentItem command
\usepackage{enumitem}
\usepackage{changepage}

%For \textrightarrow
\usepackage{textcomp}
\usepackage{tgpagella}
 
%For Gantt Chart
\usepackage{xspace}
\usepackage{pgfgantt}
\usepackage{subcaption}
 
\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}

\usepackage{geometry}
\geometry{textheight=9.5in, textwidth=7in}
\setlength\parindent{0pt}

\usepackage{xspace}
\usepackage{pgfgantt}
\usepackage{subcaption}

% 1. Fill in these details
\def \CapstoneTeamName{\textbf{Insert Team Name Here} }
\def \CapstoneTeamNumber{8}
\def \GroupMemberOne{James Stallkamp}
\def \GroupMemberTwo{Jeremy Fischer}
\def \GroupMemberThree{Austin Row}
\def \CapstoneProjectName{\botname}
\def \CapstoneSponsorCompany{Autodesk}
\def \CapstoneSponsorPerson{Patti Vrobel}
\def \botname{Kora\xspace}
\def \speechToText{Wit.ai\xspace}


% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{		%Problem Statement
				%Requirements Document
				%Technology Review
				Design Document
				%Progress Report
				}

\newenvironment{indentItem}[1][1cm]{\begin{adjustwidth}{#1}{}}{\end{adjustwidth}}
\newcommand{\designConcernDef}[3]{
    \subsection{#1}\label{#1}
        \begin{tabular}[t]{r p{6in}}
            Stakeholder(s): & #2 \\
            Concern: & #3 \\
        \end{tabular}
}
\newcommand{\designConcernRef}[1]{
    #1 (defined in section \ref{#1})
}
\newcommand{\designElementDef}[4]{
    \subsubsection{#1}\label{#1}
        \begin{tabular}[t]{r p{6in}}
            Type: & #2 \\
            Purpose: & #3 \\
            Author: & #4 \\
        \end{tabular}
}
\newcommand{\designElementRef}[1]{
    \subsubsection{#1}
        See section \ref{#1} for element definition.
}
\newcommand{\NameSigPair}[1]{\par
\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
\par\vspace{-12pt} \textit{\tiny\noindent
\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{titlepage}
    \pagenumbering{gobble}
    \begin{singlespace}
    	\includegraphics[height=4cm]{coe_v_spot1}
        %\hfill 
        % 4. If you have a logo, use this includegraphics command to put it on the coversheet.
        \par\vspace{.2in}
        \centering
        \scshape{
            \huge CS Capstone \DocType \par
            {\large\today}\par
            \vspace{.5in}
            \textbf{\Huge\CapstoneProjectName}\par
            \vfill
            {\large Prepared for}\par
            \Huge \CapstoneSponsorCompany\par
            \vspace{5pt}
            {\Large\NameSigPair{\CapstoneSponsorPerson}\par}
            {\large Prepared by }\par
            Group\CapstoneTeamNumber\par
            % 5. comment out the line below this one if you do not wish to name your team
            %\CapstoneTeamName\par 
            \vspace{5pt}
            {\Large
                \NameSigPair{\GroupMemberOne}\par
                \NameSigPair{\GroupMemberTwo}\par
                \NameSigPair{\GroupMemberThree}\par
            }
            \vspace{20pt}
        }
        \begin{abstract}
			This Document describes the design views and components of \botname.
			This document begins by introducing the purpose, scope, and glossary, followed by a summary of the overall project.
			Then follows a list of stakeholders and their concerns.
			The rest of this document is divided into sections where each provides a different design viewpoint.
        \end{abstract}     
    \end{singlespace}
\end{titlepage}
\newpage
\pagenumbering{arabic}
\tableofcontents
% 7. uncomment this (if applicable). Consider adding a page break.
%\listoffigures
%\listoftables
\clearpage

% 8. now you write!
\section{Document Details}
	\subsection{Date of Issue and Status}
		This document was issued December 1, 2017 and is the first complete iteration of the design document.

	\subsection{Authorship}
		Jeremy Fischer, Austin Row, and James Stallkamp are the authors of this document and the developers of \botname.
		
	\subsection{Change History}
		\begin{table}[H]
			\centering
			\caption{Change History}
			\label{my-label}
			\begin{tabular}{|l|l|}
				\hline
				\textbf{Date}     & \textbf{Change Description}   \\ \hline
				November 30, 2017 & {First design document draft} \\ \hline
			\end{tabular}
		\end{table}

\section{Introduction}
	\subsection{Purpose}
		The purpose of this design document is to outline how \botname's functionality will be achieved.
		More generally, this document describes how the client's requirements will be met.
		\botname's developers will use this document as a roadmap during implementation.

	\subsection{Scope}
		This document focuses on the relationships between \botname's components and their individual processes, and how they work together to satisfy the project's requirements.
	
	
	\subsection{Summary}
		\botname will be a speech-based virtual assistant for Fusion that lets users perform any one of a subset of tasks within the product, such as saving a document or opening a menu, by verbally instructing it to perform the task.
		Workflows in Fusion that are not suited for handling by a voice interface will not be supported by \botname.
		As a stretch goal, \botname will be capable of questioning the user and using responses to predict and automatically assist with future user behavior.
		This functionality will be implemented as a plugin that is bundled with Fusion and will be part of the product's standard download. 
        \\[0.1in]		
		\botname will offer users a tool that decreases the time required to achieve their goals within Fusion by offering an interface that runs in parallel with and complements the keyboard and mouse.
		If the stretch goal is achieved, \botname will further increase productivity by learning to predict and automate specific workflows within the product.

\section{Glossary}
	\begin{table}[H]
		\centering
		\caption{Glossary}
		\label{my-label}
		\begin{tabular}{|l|l|}
			\hline
			\textbf{Term} & \textbf{Definition} \\ \hline
			\botname & The virtual assistant that is the focus of this project \\ \hline
			NLP & Natural Language Processing \\ \hline
			API & Application Programing Interface \\ \hline
			CAD & Computer Aided Design \\ \hline
			CAM & Computer Aided Manufacturing \\ \hline
            UI & User Interface \\ \hline
			Fusion & An Autodesk Cloud-based 3D CAD/CAM tool/product \\ \hline
			Task & In the context of Fusion, a function or operation that can be performed in Fusion \\ \hline
			Plugin & Software that adds specific new functionality to another piece of software \\ \hline
			User & A person that interacts with \botname or Fusion depending on the context \\ \hline
			Workflow & A sequence of related tasks \\ \hline
		\end{tabular}
	\end{table}

\section{Design Stakeholders and Concerns}
    \designConcernDef{System Decomposition}{Developers}{How is the software system decomposed into components?}
    \designConcernDef{Component Functional Responsibilities}{Developers}{What functionality is each software component responsible for?}
    \designConcernDef{User-Application Interface}{Client, Developers}{What interfaces will exist for users to interact with the application and for the application to communicate with users?}
    \designConcernDef{Internal Interfaces}{Developers}{What internal interfaces will exist between software components?}
    \designConcernDef{Component Interactions}{Developers}{Which components of the software system will interact?}
    \designConcernDef{Component Interaction Responsibilities}{Developers}{What are the responsibilities of each component of the software system in the context of interactions?}
	\designConcernDef{Architecture}{Developers}{What architecture defines the software system?}
	\designConcernDef{System States}{Developers}{What are the possible states the software system can be in?}
	\designConcernDef{State Activities}{Developers}{What defines each of the states of the system?}
	\designConcernDef{State Transitions}{Developers}{When does the system transition from one state to another?}
	\designConcernDef{Log File Location}{Developers}{Where will data regarding user interactions be logged?}
	\designConcernDef{Log File Content}{Developers}{What will be stored in log files?}
	\designConcernDef{Log File Access}{Developers}{How will stored log files be accessed?}
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                           ***NOTES***
%
% Addressed Design Concerns:
%    1) Should specify by ID each of the concerns from the "Design Stakeholders and Concerns"
%       that are being addressed or discussed in that particular viewpoint.
%
% Design Elements: 
%    1) If element is not previously defined in other viewpoint, then offer definition. 
%       Otherwise reference definition in other viewpoint (e.g. "See 4.5.2")
%
% Design Rationale:
%    1) There won't be a single section for design rationale. As per the IEEE standards doc,
%       the design rationale should be justification for decisions made in the desing and
%       it doesn't need a dedicated section. Just make sure to include justification for 
%       why we chose to do something in a certain way (e.g. "Use of the Mediator design pattern
%       allows the application to...")
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Design Viewpoint: Composition}
    \subsection{Addressed Design Concerns}
        \begin{itemize}
            \item \designConcernRef{System Decomposition}
            \item \designConcernRef{Component Functional Responsibilities}
        \end{itemize}

    \subsection{Design Elements} 
        \designElementDef{Master Module}
                         {Module}
                         {Facilitates communication between modules and manages application state.}
                         {James Stallkamp}
        \designElementDef{UI Module}
                         {Module}
                         {Provides user a way to interact with \botname and expresses the application state to the user.}
                         {James Stallkamp}
        \designElementDef{Speech-to-Intent Module}
                         {Module}
                         {Anaylzes speech input and produces a intent object in JSON format.}
                         {James Stallkamp}
        \designElementDef{Logger Module}
                         {Module}
                         {Stores runtime and contextual information to be used for training \botname.}
                         {James Stallkamp}
        \designElementDef{Fusion Module}
                         {Module}
                         {Translates intent into Fusion API commands and executes them.}
                         {James Stallkamp}
        \designElementDef{Text-to-Speech Module}
                         {Module}
                         {Synthesizes an audio output from a given text input.}
                         {James Stallkamp}
        \designElementDef{Action Prediction Module}
                         {Module}
                         {Trains \botname to become a more powerful assistant.}
                         {James Stallkamp}
						 
    \subsection{Design View: Modules}
		\botname is composed of seven primary modules.
		\subsubsection{Master Module}
			\begin{indentItem}
				The Master module is responsible for coordinating all other modules.
			\end{indentItem}
		\subsubsection{UI Module}
			\begin{indentItem}
				The UI module is responsible for all interaction with the user.
				This module will collect input and communicate it to the Master module as well output regular feedback to the user.
			\end{indentItem}
		\subsubsection{Speech-to-Intent Module}
			\begin{indentItem}
				The Speech-to-Intent module will take in audio input and output a JSON object containing information on the spoken input.
				This intent module will construct the JSON object and return it to master.
			\end{indentItem}
		\subsubsection{Logger Module}
			\begin{indentItem}
				The Logger Module will create a persist-able data object that will be loaded with run time information from \botname.
				These data objects will be analyzed and used to help train \botname for future development.
			\end{indentItem}
		\subsubsection{Fusion Module}
			\begin{indentItem}
				The next module is the Fusion module, this module will handle executing Fusion commands.
				The Fusion module will parse information from the JSON intent object to construct and execute a Fusion command.
			\end{indentItem}
		\subsubsection{Text-to-Speech Module}
			\begin{indentItem}
				In order for \botname to speak to the user it will need a voice synthesizer module.
				This module will receive text input and produce an audio output that can be played to the user.
			\end{indentItem}		
		\subsubsection{Action Prediction Module}
			\begin{indentItem}
				The Action Prediction module is responsible for training \botname to recognize patterns and improve functionality.
			\end{indentItem}
		
\section{Design Viewpoint: Information}
	\subsection{Addressed Design Concerns}
		\begin{itemize}
			\item \designConcernRef{Log File Location}
			\item \designConcernRef{Log File Content}
			\item \designConcernRef{Log File Access}
		\end{itemize}


	\subsection{Design Elements}
		\designElementDef{MongoDB}{Database}{Database to hold the log files}{Jeremy Fischer}
		\designElementDef{JSON object}{Storage structure}{The structure the information will be stored in}{Jeremy Fischer}
		\designElementDef{HTTP calls}{Access mechanism}{How the data will be posted and accessed}{Jeremy Fischer}
	
	\subsection{Design View: Contents}
		The contents of the data will be:
		\begin{itemize}
			\item the intent generated by the Speech-to-Intent module
			\item the context generated by the Speech-to-Intent module such as quantities
			\item whether the user's request was successfully processed
			\item the posting date
			\item the posting time
			\item the user identification
		\end{itemize}
	
	\subsection{Design View: Access}
		The data will be posted and accessed via HTTP calls to the database.
	
	\subsection{Design View: Structure}
		The data will be stored in a MongoDB database.
		Each entry in the database will resemble the JSON object that is returned from the Speech-to-Intent module driver method.
		
		

\section{Design Viewpoint: Patterns}
    \subsection{Addressed Design Concerns}
        \begin{itemize}
            \item \designConcernRef{Architecture}
        \end{itemize}

    \subsection{Design Elements}
		\designElementDef{Mediator Design Framework}
						 {System Architecture}
						 {\botname has a simple mediator that coordinates all interactions between all other components.}
						 {James Stallkamp}
    \subsection{Design View: Software Architecture}
		\botname is structured according to a mediator design pattern. 
		\botname will have a Master module that coordinates interactions between itself and all other modules.
		The Master module controls \botname's flow and ensures that the correct data gets to the correct module.


\section{Design Viewpoint: Interfaces}
    \subsection{Addressed Design Concerns}
        \begin{itemize}
            \item \designConcernRef{User-Application Interface}
            \item \designConcernRef{Internal Interfaces}
        \end{itemize}

    \subsection{Design Elements}
        \designElementDef{UI Module Interface}{Internal Interface}{Defines rules governing interactions with the UI module.}{Austin Row}
        \designElementDef{Speech-to-Intent Module Interface}{Internal Interface}{Defines rules governing interactions with the Speech-to-Intent module.}{Austin Row}
        \designElementDef{Logging Module Interface}{Internal Interface}{Defines rules governing interactions with the Logging module.}{Austin Row}
        \designElementDef{Text-to-Speech Module Interface}{Internal Interface}{Defines rules governing interactions with the Text-to-Speech module.}{Austin Row}
        \designElementDef{Fusion Module Interface}{Internal Interface}{Defines rules governing interactions with the Fusion module.}{Austin Row}
        \designElementDef{Action Prediction Module Interface}{Internal Interface}{Defines rules governing interactions with the Action Prediction module.}{Austin Row}
        \designElementDef{User Interface}{External Interface}{Defines rules governing how the human user can interact with \botname.}{Austin Row}
    \subsection{Design View: Module Interfaces}
        The various modules that compose the project each have an interface defined by functions that are unique to that module.
        Following is documentation for the functions that define the interface to each module.
        \subsubsection{UI Module Interface}
            \begin{tabular}[t]{l p{6in}}
                \hline
                Function: & notify \\
                Description: & Shows a notification to the user in the Fusion editor. \\
                Parameters: & notification -- a KoraNotification object that contains members to specify visual characteritics and content for notification that is shown to user. \\
                Return: & 1 on successful showing of notification, 0 otherwise. \\
                \hline
                Function: & listen \\
                Description: & Listens through microphone until user voice command is given then returns data about the command. \\
                Parameters: & N/A \\
                Return: & Wit.ai JSON response object with data from user command. \\
                \hline
                Function: & voicePrompt \\
                Description: & Asks user a question via a voice sythesizer and records and interprets response. \\
                Parameters: & text -- the text manuscript for the question that the user should be asked. \\
                            & timeout (optional) -- the amount of time that \botname should wait for a response before giving up. \\
                Return: & Wit.ai JSON response object with data from user response. \\
                \hline
            \end{tabular}

        \subsubsection{Speech-to-Intent Module Interface}
            \begin{tabular}[t]{l p{6in}}
                \hline
                Function: &  streamAudioToWit \\
                Description: & Streams audio data to Wit.ai via provided audio stream and returns Wit.ai JSON response object. \\
                Parameters: & audioStream -- an Pyaudio input stream. \\
                Return: & Wit.ai JSON response object for streamed audio. \\
                \hline
            \end{tabular}
            
        \subsubsection{Logging Module Interface}
            \begin{tabular}[t]{l p{6in}}
                \hline
                Function: & debug \\
                Description: & Logs data to log file with DEBUG tag. \\
                Parameters: & message -- string with message to be logged. \\
                Return: & 1 on message successfully being added to log file, 0 otherwise. \\
                \hline
                Function: & warn \\
                Description: & Logs data to log file with WARN tag. \\
                Parameters: & message -- string with message to be logged. \\
                Return: & 1 on message successfully being added to log file, 0 otherwise. \\
                \hline
                Function: & error \\
                Description: & Logs data to log file with ERROR tag. \\
                Parameters: & message -- string with message to be logged. \\
                Return: & 1 on message successfully being added to log file, 0 otherwise. \\
                \hline
            \end{tabular}
            
        \subsubsection{Text-to-Speech Module Interface}
            \begin{tabular}[t]{l p{6in}}
                \hline
                Function: & textToSpeech \\
                Description: & Converts message given as text to raw audio and returns audio. \\
                Parameters: & text -- the text to be converted to audio. \\
                Return: & List object containing raw audio data for text. \\
                \hline
            \end{tabular}
 
        \subsubsection{Fusion Module Interface}
            \begin{tabular}[t]{l p{6in}}
                \hline
                Function: & executeCommand \\
                Description: & Uses Fusion API to execute command(s) specified in Wit.ai JSON response object passed as argument. \\
                Parameters: & command -- a Wit.ai JSON response object with data needed to interpret user's command. \\
                            & callback (optional) -- a function that accepts an integer associated with a command execution status to be called at the finish of executeCommand. \\
                Return: & An integer code associated with a particular status (e.g. success, runtime failure, unrecognized command, etc.). \\
                \hline
            \end{tabular}    

        \subsubsection{Action Prediction Module Interface}
            \begin{tabular}[t]{r p{6in}}
                \hline
                Function: & predict \\
                Description: & Uses a Wit.ai JSON response object to predict what user's next command will be. \\
                Parameters: & command -- a Wit.ai JSON response object with data derived from a user voice command. \\
                Return: & A JSON object containing prediction for next user voice command and unique integer ID to identify prediction. \\
                \hline
                Function: & learn \\
                Description: & Gives feedback to \botname's prediction model so that it can improve. \\
                Parameters: & predictionID -- unique integer identifier for a previous prediction made by the model. \\
                            & actual -- JSON with data regarding what the user actually did after the model made its prediction. \\
                Return: & N/A \\
                \hline
            \end{tabular}

    \subsection{Design View: User Interface}
        The user interface can be divided into two interaction types: the user giving \botname a command and \botname replying to the user with the application status. 
        There are two use patterns for a user when they give \botname a command. The first way to give a command is to say the wake word followed by the command.
        When the user says the wake word, it signals to \botname that it should be actively listening for a command.
        The other method is to click the wake button that acts as an alternative to the wake word then say the command.  
        \\[0.1in]

        Through the user interface, the application responds back to the user with the status of the previous command.
        If the command succeeds, the application uses a voice synthesizer to alert the user that the previous command succeeded.
        If the command fails, the application uses the voice synthesizer to alert the user that the previous command failed.

\section{Design Viewpoint: Interactions}
    \subsection{Addressed Design Concerns}
        \begin{itemize}
            \item \designConcernRef{Component Interactions}
            \item \designConcernRef{Component Interaction Responsibilities}
        \end{itemize}

    \subsection{Design Elements}
        \designElementRef{Master Module}
        \designElementRef{UI Module}
        \designElementRef{Speech-to-Intent Module}
        \designElementRef{Logger Module}
        \designElementRef{Fusion Module}
        \designElementRef{Text-to-Speech Module}
        \designElementRef{Action Prediction Module}

    \subsection{Design View: Module Interactions}
        The following diagram specifies the interactions that occur between modules within the application: 
		\begin{figure}[H]
            \includegraphics[width=1\textwidth]{componentInteractions-1.eps}
			\centering
            \caption{The interactions that occur between the system's software modules (part 1). Continued on next page.}
			\label{fig::componentInteractions-1}
		\end{figure}
        \begin{figure}[H]
			\includegraphics[width=1\textwidth, height=1\textheight]{componentInteractions-2.eps}
			\centering
            \caption{The interactions that occur between the system's software modules (part 2).}
			\label{fig::componentInteractions-2}
		\end{figure}

\section{Design Viewpoint: State Dynamics}
	\subsection{Addressed Design Concerns}
		\begin{itemize}
			\item \designConcernRef{System States}
			\item \designConcernRef{State Activities}
			\item \designConcernRef{State Transitions}
		\end{itemize}
		
	\subsection{Design Elements}
		\designElementDef{Idle Listen}{State}{\botname is waiting for a wake action to take place}{Jeremy Fischer}
		\designElementDef{Active Listen}{State}{\botname begins listening to the user}{Jeremy Fischer}
		\designElementDef{Process Speech}{State}{\botname is deriving intent from the user's verbal request}{Jeremy Fischer}
		\designElementDef{Endpoint Mapping}{State}{\botname is discerning which API endpoint to call}{Jeremy Fischer}
		\designElementDef{Fusion Action}{State}{\botname makes the Fusion API call}{Jeremy Fischer}
		\designElementDef{UI Feedback}{State}{\botname is verbalizing the state of the latest request to the user}{Jeremy Fischer}
		\designElementDef{Error}{State}{\botname is in a state of error}{Jeremy Fischer}
	
	
	\subsection{Design View: States} 
		\subsubsection{State Diagram}
			\begin{figure}[H]
				\includegraphics[width=1\textwidth, height=.35\textheight]{stateDynamics.eps}
				\centering
				\caption{The possible states \botname can be in, as well as the states the system can transfer to from within a given state.}
				\label{fig::stateD}
			\end{figure}
	
	\subsection{Design View: State Activity}
		\subsubsection{Idle Listen}
			\begin{indentItem}
				The Speech-to-Intent module is being streamed audio, but does not do anything with it until it hears the wake word or is signaled to via a wake action such as a button press.
				In this state the system is simply awaiting for the user to signal it to begin listening.
			\end{indentItem}
	
	\subsubsection{Active Listen}
		\begin{indentItem}
			The system tells the Speech-to-Intent module that it should treat the incoming audio as a request.
		\end{indentItem}
	
	\subsubsection{Process Speech}
		\begin{indentItem}
			The Speech-to-Intent module is being streamed audio and is attempting to gather intent and context from it.
		\end{indentItem}
	
	\subsubsection{Endpoint Mapping}
		\begin{indentItem}
			\botname is attempting to discern the correct Fusion API endpoint based off of the intent and context variables in the JSON received from the Speech-to-Intent module.
		\end{indentItem}
		
	\subsubsection{Fusion Action}
		\begin{indentItem}
			\botname is making the call to the Fusion API and then waiting for the API to return an error code.
		\end{indentItem}
	
	\subsubsection{UI Feedback}
		\begin{indentItem}
			\botname is signaling feedback regarding the latest transaction to the user.
		\end{indentItem}
	
	\subsubsection{Error}
		\begin{indentItem}
			The system is in a state of failure and is resetting the application so \botname can attempt another request.
		\end{indentItem}
	
	
	\subsection{Design View: State Transitions}	
		\subsubsection{Idle Listen}
			\begin{itemize}
				\item \textit{Idle Listen \textrightarrow{}  Active Listen}
				\begin{indentItem}
					\botname moves from the Idle Listen state to the Active listen state when a wake action takes place.
				\end{indentItem}
			\end{itemize}
		
		\subsubsection{Active Listen}
		\begin{itemize}
			\item \textit{Active Listen \textrightarrow{}  Process Speech}
			\begin{indentItem}
				\botname moves from the Active Listen state to the Process Speech state when the Speech-to-Intent module does not receive speech for a half second.
			\end{indentItem}
			\item \textit{Active Listen \textrightarrow{}  Error}
			\begin{indentItem}
				\botname moves from the Active Listen state to the Error state when an internal failure occurs when \botname is in the Active Listen state.
			\end{indentItem}
		\end{itemize}
		
		\subsubsection{Process Speech}
		\begin{itemize}
			\item \textit{Process Speech \textrightarrow{} Endpoint Mapping}
			\begin{indentItem}
				\botname moves from the Process Speech state to the Endpoint Mapping state when the Speech-to-Intent module returns the JSON object holding the processed speech's intent and arguments.
			\end{indentItem}
			\item \textit{Process Speech \textrightarrow{} Error}
			\begin{indentItem}
				\botname moves from the Process Speech state to the Error state when an internal failure occurs when \botname is in the Process Speech state.
			\end{indentItem}
		\end{itemize}
		
		\subsubsection{Endpoint Mapping}
		\begin{itemize}
			\item \textit{Endpoint Mapping \textrightarrow{} Fusion Action}
			\begin{indentItem}
				\botname moves from the Endpoint Mapping state to the Fusion Action state when the Mapping module successfully maps the intent to a Fusion API command.
			\end{indentItem}
			\item \textit{Endpoint Mapping \textrightarrow{} UI Feedback}
			\begin{indentItem}
				\botname moves from the Endpoint Mapping state to the UI Feedback state when the Mapping module fails to map the intent to a Fusion API command.
			\end{indentItem}
			\item \textit{Endpoint Mapping \textrightarrow{} Error}
			\begin{indentItem}
				\botname moves from the Endpoint Mapping state to the Error state when an internal failure occurs when \botname is in the Process Speech state.
			\end{indentItem}
		\end{itemize}
		
		\subsubsection{Fusion Action}
		\begin{itemize}
			\item \textit{Fusion Action \textrightarrow{} UI Feedback}
			\begin{indentItem}
				\botname moves from the Fusion Action state to the UI Feedback state when the Fusion API returns the error code indicating whether the API call was successful or not.
			\end{indentItem}
			\item \textit{Fusion Action \textrightarrow{} Error}
			\begin{indentItem}
				\botname moves from the Fusion Action state to the Error state when an internal failure occurs when \botname is in the Fusion Action state.
			\end{indentItem}
		\end{itemize}
		
		\subsubsection{UI Feedback}
		\begin{itemize}
			\item \textit{UI Feedback \textrightarrow{} Idle Listen}
			\begin{indentItem}
				\botname moves from the UI Feedback state to the Idle Listen state after it indicates to the user the outcome of processing the request.
			\end{indentItem}
			\item \textit{UI Feedback \textrightarrow{} Error}
			\begin{indentItem}
				\botname moves from the UI Feedback state to the Error state when an internal failure occurs when \botname is in the UI Feedback state.
			\end{indentItem}
		\end{itemize}
		
		\subsubsection{Error}
		\begin{itemize}
			\item \textit{Error \textrightarrow{} Idle Listen}
			\begin{indentItem}
				\botname moves from the Error state to the UI Feedback state after it resets all internal variables to their initial state.
			\end{indentItem}
		\end{itemize}

\section{Gantt Chart}
   	\begin{figure}[H]
		\begin{center}
			%\includegraphics[width=1\textwidth]{ganttChart.eps}
			%Changed Gantt chart to be modifiable.
			\begin{ganttchart}[
				y unit title=0.4cm,
				y unit chart=0.5cm,
				vgrid,
				hgrid,
				title left shift=.05, 
				title right shift=.05, 
				title height=1, 
				group right shift=0
				]{1}{24}
				\gantttitle{Months}{24} \\
				\gantttitle{January}{4} 
				\gantttitle{February}{4} 
				\gantttitle{March}{4} 
				\gantttitle{April}{4} 
				\gantttitle{May}{4} 
				\gantttitle{June}{4} \\

				
				\ganttbar{MongoDB Creation}{1}{2} \\
				\ganttbar{Module Skeletons Creation}{1}{2} \\
				\ganttbar{Speech-to-Intent Working}{2}{3} \\
				\ganttbar{Text-to-Speech Working}{3}{3} \\
				\ganttbar{Fusion API Mapping}{2}{5} \\
				\ganttbar{Pipeline Connected}{4}{9} \\
				\ganttbar{Alpha Demo Creation}{9}{11} \\	
				\ganttbar{Performance Testing}{9}{12} \\
				\ganttbar{Train NLP Modules}{13}{20} \\
				\ganttbar{Beta Demo Creation}{17}{24} \\
				\ganttbar{Smart Assistant Stretch Goal}{15}{23} \\
				\ganttbar{Engineering Expo}{24}{24}
				
			\end{ganttchart}
			\captionsetup{justification=centering}
			\caption{\botname Development Schedule}
			\label{fig:developmentSchedule1}
		\end{center}
	\end{figure}

			
\section{Conclusion}
	This document has described \botname's development roadmap.
	This document explains how \botname's underlying system is decomposed into components and what each component is responsible for.
	Above is a Gantt chart that details the development schedule which the \botname developers will abide by.
	There is a change history table at the beginning of this document which will explain any modifications made to the design described in this document.

%\bibliographystyle{IEEEtran}
%\bibliography{references.bib}



\end{document}
