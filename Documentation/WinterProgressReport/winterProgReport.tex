\documentclass[onecolumn, draftclsnofoot,10pt, compsoc]{IEEEtran}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{url}
\usepackage{setspace}
 
\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage{url}



\usepackage{geometry}
\geometry{textheight=9.5in, textwidth=7in}
\setlength\parindent{0pt}
\setlength{\parskip}{1em}


\usepackage{tabu}
\usepackage{longtable}

\usepackage{xspace}
\usepackage{pgfgantt}
\usepackage{subcaption}
\usepackage{comment}

% 1. Fill in these details
\def \CapstoneTeamNumber{8}
\def \GroupMemberOne{Austin Row}
\def \GroupMemberTwo{Jeremy Fischer}
\def \CapstoneProjectName{Kora}
\def \CapstoneSponsorCompany{Autodesk}
\def \CapstoneSponsorPersonOne{Anand Karyekar}
\def \CapstoneSponsorPersonTwo{Jennifer Talaga}
\def \botname{Kora\xspace}

% 2. Uncomment the appropriate line below so that the document type works
\def \DocType{		%Problem Statement
				%Requirements Document
				%Technology Review
				%Design Document
				Winter Progress Report
				}
			
\newcommand{\NameSigPair}[1]{\par
\makebox[2.75in][r]{#1} \hfil 	\makebox[3.25in]{\makebox[2.25in]{\hrulefill} \hfill		\makebox[.75in]{\hrulefill}}
\par\vspace{-12pt} \textit{\tiny\noindent
\makebox[2.75in]{} \hfil		\makebox[3.25in]{\makebox[2.25in][r]{Signature} \hfill	\makebox[.75in][r]{Date}}}}
% 3. If the document is not to be signed, uncomment the RENEWcommand below
\renewcommand{\NameSigPair}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\begin{titlepage}
    \pagenumbering{gobble}
    \begin{singlespace}
    	\includegraphics[height=4cm]{coe_v_spot1}
        %\hfill 
        % 4. If you have a logo, use this includegraphics command to put it on the coversheet.
        \par\vspace{.2in}
        \centering
        \scshape{
            \huge CS Capstone \DocType \par
            {\large\today}\par
            \vspace{.5in}
            \textbf{\Huge\CapstoneProjectName}\par
            \vfill
            {\large Prepared for}\par
            \Huge \CapstoneSponsorCompany\par
            \vspace{5pt}
            {\Large\NameSigPair{\CapstoneSponsorPersonOne}\par
            \Large\NameSigPair{\CapstoneSponsorPersonTwo}\par}
            {\large Prepared by }\par
            Group\CapstoneTeamNumber\par
            % 5. comment out the line below this one if you do not wish to name your team
            %\CapstoneTeamName\par 
            \vspace{5pt}
            {\Large
                \NameSigPair{\GroupMemberOne}\par
                \NameSigPair{\GroupMemberTwo}\par
            }
            \vspace{20pt}
        }
        \begin{abstract}
			This document outlines the production progress of Kora from December 2017 through the middle of February 2018, including obstacles and steps moving forward.
			The biggest obstacle we've encountered is Kora's latency time, which is roughly seven and a half seconds.
			Because of that, moving forward our top priority is to reduce Kora's latency.
        \end{abstract}     
    \end{singlespace}
\end{titlepage}
\newpage
\pagenumbering{arabic}
\tableofcontents
% 7. uncomment this (if applicable). Consider adding a page break.
%\listoffigures
%\listoftables
\clearpage


\section{Purpose}
	Kora is a proof of concept project that will integrate a natural language processing library into Autodesk's 3-D computer aided design software, Fusion.
	Kora will be a speech-based virtual assistant for Fusion that lets users perform a subset of tasks within the product, such as saving a document or opening a menu, by verbally instructing it to perform the task.
	As a stretch goal, Kora will be capable of questioning the user and using responses to predict and automatically assist with future user behavior.
	
	Kora will offer users a tool that decreases the time required to achieve their goals within Fusion by offering an interface that runs in parallel with and complements the keyboard and mouse.
	If the stretch goal is achieved, Kora will further increase productivity by learning to automate specific workflows within the product.

\section{Goals}
	\subsection{Main Goals}
		\begin{itemize}
			 \item
		 	Kora will allow the user to perform tasks in Fusion via a voice interface.
			Each voice command given by the user will be mapped to a specific task which will then be performed in the open Fusion editor.
			
			\item
			All interactions with Kora will be logged for debugging and future development purposes.
			
		\end{itemize}
	\subsection{Stretch Goals}
		\begin{itemize}
			\item
			Kora will periodically ask the user questions regarding why they have performed specific tasks.
			The questions asked by Kora will pertain to specific predefined contexts.
			
			\item
			Kora will record user responses and save a transcript along with contextual information.
			
			\item
			User responses to interview questions will be used to try to predict and assist with future user actions.
		\end{itemize}

    \begin{comment} 
        ---Obstacles---
            1) Platform Compatibility
            2) Rotate is not natively supported in Fusion API
            3) Add-Ins are run in same thread as Fusion Editor and thus block use of editor when running
            4) WIT response latency is currently too high
            5) Add-Ins are run in own environment containing only default python modules (non-default python modules not supported, must self include)
    \end{comment} 
    \begin{comment} 
	    ---Features---
		    1) Logging/MongoDB
		    2) Streaming to WIT/WIT response
		    3) Supported Commands (i.e. rotate, though it'd be easy to put save in there before this is due)
		    4) Automatic WIT training via Selenium
		    5) Kora running as an Add-In in the background (contrast to it being a script)
    \end{comment} 
	\begin{comment} 
		--Moving Forward---
			1) Reduce NLP latency (probably by implementing some form of NLP locally either through other open source library or own implementation)
			2) Implement UI messages via some python GUI framework to alert user to status of command (understood and working, not understood, etc.)
			3) Handle silence from user (don't trying processing commands when user has not given one)
			4) Implement unit tests
	\end{comment}

	\begin{comment}
	--Individual Grading---
		a. Description of current status of personal portion of project (2/2 points)
		b. What’s left to do (2/2 points)
		c. Problems impeding personal and group progress/Solutions (2/2 points)
		d. Other relevant/interesting information about project (2/2 points)
	\end{comment}


\section{Jeremy}
 
    \subsection{Obstacles}
	    %1
	    \subsubsection{Cross Platform Compatibility}
		    As per our requirements, Kora must function on both Windows and MacOS.
		    This has caused subtle issues that were challenging to track down.
		    An issue in particular was PyAudio, the library used to stream audio to WIT.ai.
		    Kora with PyAudio worked fine on Windows, however, when trying to run Kora with Pyaudio on Mac Fusion would crash without error messages or hints.
		    The rainbow spinning wheel on Mac would start spinning and three seconds later Fusion would shut down.
		    After some thorough investigating we found that the problem occurred for two reasons.
		    The first was Pyaudio's use of the shared object file called\_portaudio.so.
		    The version of \_portaudio.so we had in the repo was meant solely for the Windows operating system.
		   	The second was that the default microphone sample rate on Windows is significantly lower than the default sample rate on Mac.
		   	This meant that with Pyaudio's default values for chunk size, sample rate, and number of channels, Mac's microphone would fill up PyAudio's streaming buffer used to record the user's voice faster than Pyaudio was ready for.
		    This caused an overflow which resulted in Fusion crashing.
		    
		    We assume that subtle issues will continue to arise in making Kora cross platform compatible.
		    Moving forward we will do more incremental testing so if there is another issue we will be able to pinpoint the source of it much faster. 
	    
	    %4
	    \subsubsection{Latency}
		    Kora being a voice assistant means it must be able to execute commands quickly.
		    Users won't use Kora if they command her to do something and then have to wait approximately seven and a half seconds before she accomplishes it.
		    Unfortunately, this is Kora's current average speed.
		    The problem lies within WIT.ai, the library we are using as our natural language processor.
		    WIT is on the web and Kora has to stream the user's speech to it via HTTP calls.
		    This on average takes seven and a half seconds.
		    Currently we don't exactly know why it's taking so long, but we have a few guesses.
		    
    
	    %5
	    \subsubsection{Using Non-Default Python Modules}
		    Fusion Add-Ins and Scripts are run in their own environment.
		    They have their own version of Python and their own Python modules.
		    This has been tricky for two reasons.
		    The first is pathing.
		    Since Fusion's Python only looks for libraries within its own environment we either have to append the directory of our newly downloaded library to the system path, causing a bloated system path variable, or change all of the absolute import paths in the library to relative imports.
		    It's not possible to move the libraries Kora uses to Fusion's Python folder, because that folder gets rewritten each update.
		    To abide by good practices we have been changing the import paths to relative paths, but moving forward that may not be plausible depending on the size of the new libraries we include.
		    The second is library versions.
		    We have ran into issues where we pip install a library via our command line and it downloads the Python 2.7 version since that is what we are using locally.
		    Then, when we move the library into Kora Fusion crashes because Fusion's built in Python is Python 3.3 which isn't always compatible with libraries built for Python 2.7.

		
	\subsection{Project Progress}
		%1
		\subsubsection{User Interaction Logging with MongoDB}
			Kora's MongoDB database will have two collections: Interaction and Logs.
			The Interaction collection is setup and functioning locally.
			The Interaction collection stores documents describing each user-Kora interaction.
			Each document contains the posting date, the user's Fusion ID number, the JSON returned by WIT.ai, the chosen Fusion API call, Fusion's execution status, and the time it took from when the user stopped talking to the time Fusion finished executing the command.
			
			
		%3
		\subsubsection{Supported Commands}
			Kora can now execute the two commands we marked as our baseline commands in the requirements document: "rotate", "save", and "save as".
			If the user commands Kora to save and they haven't saved the file themselves for the first time, then Kora will pop up a text input and ask the user what they want the file to be called.
			If the file has been saved before, then Kora will go ahead and seamlessly save the document.
			
			Here are a few example sentences that a user can give Kora after she is activated.
			When the user is finished speaking Kora successfully executes the command within Fusion.
			\begin{itemize}
				\item 
				Rotate $<direction> <number>$ degrees
				\item 
				Rotate $<number>$ degrees $<direction>$

				\item 
				Save
				
				\item 
				Please save this
				
				\item
				Save it

				\item 
				Save as $<file name>$
				
				\item 
				Please save this as $<file name>$
			\end{itemize}
		
		
	\subsection{Moving Forward}
		    %1
		\subsubsection{Improving Latency}
			As mentioned above in the Obstacles section, we have a big problem with Kora's latency.
			Our top priority moving forward is to solve this problem.
			We may try:
			\begin{itemize}
				\item
				Converting the speech to text locally and then sending text to WIT instead of streaming bytes of audio.
				
				\item
				Using a wake word instead of an activate button so WIT only processes the relevant bytes of audio instead of attempting to process white noise.
				
				\item
				Bringing WIT off the cloud and onto our local machines.
				
				\item
				Pivoting and using a new natural language processor altogether
			\end{itemize}
			A significant amount of our code is built upon the response returned from WIT.ai, so the sooner we have a solution to our latency problem the smaller headache we will have further down the road when refactoring our code to work with the solution.
		
		%4
		\subsubsection{Testing}
			Moving forward we will also be integrating a suite of unit tests to verify Kora's robustness.
			We are hoping to incorporate a testing library which given a testing suite can automatically run the suite after every push to the GitHub repository, or every pull from the repository.
			These tests will help us locate any weak points or subtle bugs which reside in Kora, as well as ensure that any new code submitted doesn't introduce new issues.
			Having a testing suite will also minimize the frustration when investigating which piece of new code introduced is causing a crash on the opposite operating system when testing for cross-compatibility.
			
		
	
	
	
	
	
	
\section{Austin}
    \subsection{Obstacles}
	    \subsubsection{Implementing Rotate via API}
		    One of the requirements of the project is that a user should be able to rotate their view in the editor via a voice command.
		    It was initially believed that the Fusion API would include a method specifically for rotating the view in the editor or rotating a specific object in the project by a specified magnitude.
		    In fact, no such functionality is present in the API and achieving this functionality required a slightly more in-depth exploration and use of the Fusion API than was initially anticipated.
		    Admittedly this issue arose from a lack of sufficient research into a core driver of the requirements of our project.
		    However, the functionality was eventually implemented.


   	 \subsubsection{Parallelizing Add-Ins and the Fusion Editor}
		    Part of Kora’s requirements specify that the core functionality of receiving and acting on user voice commands is able to run continuously in the background in parallel with the user’s actions within the Fusion editor.
		    It never occurred to the team that the Fusion editor may not natively support running Add-Ins in a separate thread from the editor itself which is the case.
		    This meant that we were required to self-implement a work around that allowed Kora to run in the background as intended which was a task that we had not expected to have to complete.


    	\subsubsection{Using API in Parallelized Add-In}
		    Compounding the problem of the lack of native support for running Add-Ins in parallel with the Fusion editor was the fact that calling most Fusion API functions within a self-spawned thread results in the editor crashing.
		    This complicated the solution for achieving Kora’s continuous-listening functionality by requiring that listening for and recording a user’s voice commands occur in a self-spawned thread while acting on these commands must happen back in the main thread.
		    This was eventually solved and implemented using Custom events provided by the Fusion API as a work around for this well-known problem.


	\subsection{Project Progress}
    	\subsubsection{Natural Language Processing of Speech Audio}
		    Kora’s intended functionality is driven by the ability to process and understand voice commands given by a user.
		    Thus, the ability to process natural language given in an audio format is crucial to achieving Kora’s desired functionality and was the first feature that was implemented.
		    As of the writing of this document, Kora can record a user speaking and can translate the recorded audio into one of several learned intents.
		    This is functionality is provided entirely by the free-to-use third-party natural language processor, WIT.
		    WIT is owned by Facebook and offers a an API that supports streaming audio data to one of their servers where the natural language processing is performed and after which an HTTP response with the derived data is returned.
		    It is this data that can then be used to interpret what should be triggered in the Fusion editor to enact the command given by the user.
		    The delay associated with making requests to the WIT servers is proving to be a significant factor in the unacceptable latency of program and thus it is likely that a different method will be used for Kora’s natural language processing in the final iteration of the project.
 
    	\subsubsection{Automated WIT Training via Selenium}
		    To resolve the issue of having to manually enter training data to train the underlying model used by WIT--a slow and tedious process--a script was developed which automates this process.
		    No API is offered to train WIT programmatically, so the script to automate this process relies on the Selenium testing module which provides ways to simulate a user interacting with a web browser.
		    This script navigates to Kora’s training page on WIT’s website using provided credentials of an existing account with access to the project.
		    From there, it takes training data that is generated through the tuning of several parameters in the script or explicitly given in the script and performs all of the necessary interactions with the browser to train WIT using the data.
		    This offers a drastically faster method for training WIT.
		    There are two issues with this, however.
		    One is that the script’s success relies on several aspects of WIT’s website not changing.
		    If the website is updated and specific entities in the HTML are changed, the script could break.
		    This is, however, the lesser of the two issues as fixing it would simply require making changes to some of the identifiers the script uses to route itself to the correct place.
		    The more serious problem is that since the project will likely end up replacing WIT with something faster for its language processing needs, the work done to create this script and obtain this functionality will be rendered useless.

 
	    \subsubsection{Running Kora Continuously in Background}
	   		One of the goals for Kora is have the application continuously listening for voice commands in parallel with what user is doing in the Fusion editor.
		    Originally it was believed that Fusion would by default ran Add-Ins, and thus Kora, in their own threads and thus would not specifically require the implementation of anything in the application to enable running continuously in parallel with the editor.
		    However, upon discovering that Fusion actually runs Add-Ins on the same thread as the editor and thus blocks use of the editor while Add-Ins are running, Python’s default threading module was used to run Kora in the background and achieve the desired functionality.
		    In doing this, a new problem was realized.
		    The Fusion API and even some of Python’s modules that are being used in Kora cannot be used within a separate spawned thread without crashing the editor.
		    This issue necessitated the use of Fusion’s Custom events for executing code that could only be executed in the main thread without crashing the editor.
		    Using these events, it was possible to make Kora fire an event that returned control of the main thread back to the Add-In and executed the desired code with data sent from Kora’s spawned thread via the fired event.
	    	After implementing this feature, Kora was able to continuously listen for commands in the background while the user interacted with the Fusion editor in the standard way.

		
	\subsection{Moving Forward}
    	\subsubsection{Implementing UI Messaging via GUI Framework}	
		    Currently the only way for Kora to send the user status messages such as “Command Received” or “Command Not Understood” in a graphical format is via the limited UI components provided by the Fusion API.
		    The functionality that these provide are intrusive to the user experience and are not intended to be used as a way to incorporate attractive communication with the user in Add-Ins.
		    To achieve the informative yet unobtrusive user experience that we desire for Kora, we will look to integrate a Python GUI framework to provide the necessary messaging to the user.

    	\subsubsection{Handling Periods of Silence}	
		    Currently Kora does not recover from timeouts when listening for commands from the user.
		    This is a problem as it is likely that there will be times when a user is using the application in during which they have extended periods of silence and do not interact with Kora.
		    Looking forward we will aim to implement a way for Kora to handle these periods of silence without issue.


\section{Conclusion}
	We have connected Kora's entire pipeline, that is: speech $\rightarrow$ Kora $\rightarrow$ WIT $\rightarrow$ Kora $\rightarrow$ Fusion API.
	In connecting this pipeline we have ran into a major issue with Kora's latency, and subtle bugs when assuring Kora is cross platform compatible.
	Moving forward we will attempt to reduce Kora's latency, integrate a testing suite, and add to the list of Kora supported commands.
	We hope to have achieved these goals by the next progress report.

\end{document}
